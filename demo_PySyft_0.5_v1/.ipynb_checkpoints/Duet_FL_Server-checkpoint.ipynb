{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "earlier-investing",
   "metadata": {},
   "source": [
    "## Join the Duet Server the Data Owner 1 connected to"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "sized-session",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎤  🎸  ♪♪♪ Joining Duet ♫♫♫  🎻  🎹\n",
      "\n",
      "♫♫♫ >\u001b[93m DISCLAIMER\u001b[0m: \u001b[1mDuet is an experimental feature currently in beta.\n",
      "♫♫♫ > Use at your own risk.\n",
      "\u001b[0m\n",
      "\u001b[1m\n",
      "    > ❤️ \u001b[91mLove\u001b[0m \u001b[92mDuet\u001b[0m? \u001b[93mPlease\u001b[0m \u001b[94mconsider\u001b[0m \u001b[95msupporting\u001b[0m \u001b[91mour\u001b[0m \u001b[93mcommunity!\u001b[0m\n",
      "    > https://github.com/sponsors/OpenMined\u001b[1m\n",
      "\n",
      "♫♫♫ > Punching through firewall to OpenGrid Network Node at:\n",
      "♫♫♫ > http://ec2-18-218-7-180.us-east-2.compute.amazonaws.com:5000\n",
      "♫♫♫ >\n",
      "♫♫♫ > ...waiting for response from OpenGrid Network... \n",
      "♫♫♫ > \u001b[92mDONE!\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fjunyuan/.local/lib/python3.8/site-packages/aiortc/rtcdtlstransport.py:211: CryptographyDeprecationWarning: This version of cryptography contains a temporary pyOpenSSL fallback path. Upgrade pyOpenSSL now.\n",
      "  _openssl_assert(lib.SSL_CTX_use_certificate(ctx, self._cert._x509) == 1)  # type: ignore\n",
      "/home/fjunyuan/.local/lib/python3.8/site-packages/aiortc/rtcdtlstransport.py:186: CryptographyDeprecationWarning: This version of cryptography contains a temporary pyOpenSSL fallback path. Upgrade pyOpenSSL now.\n",
      "  value=certificate_digest(self._cert._x509),  # type: ignore\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "♫♫♫ > \u001b[92mCONNECTED!\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import syft as sy\n",
    "duet1 = sy.join_duet(loopback=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "racial-container",
   "metadata": {},
   "source": [
    "## Join the Duet Server the Data Owner 2 connected to"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "centered-knife",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎤  🎸  ♪♪♪ Joining Duet ♫♫♫  🎻  🎹\n",
      "\n",
      "♫♫♫ >\u001b[93m DISCLAIMER\u001b[0m: \u001b[1mDuet is an experimental feature currently in beta.\n",
      "♫♫♫ > Use at your own risk.\n",
      "\u001b[0m\n",
      "\u001b[1m\n",
      "    > ❤️ \u001b[91mLove\u001b[0m \u001b[92mDuet\u001b[0m? \u001b[93mPlease\u001b[0m \u001b[94mconsider\u001b[0m \u001b[95msupporting\u001b[0m \u001b[91mour\u001b[0m \u001b[93mcommunity!\u001b[0m\n",
      "    > https://github.com/sponsors/OpenMined\u001b[1m\n",
      "\n",
      "♫♫♫ > Punching through firewall to OpenGrid Network Node at:\n",
      "♫♫♫ > http://ec2-18-218-7-180.us-east-2.compute.amazonaws.com:5000\n",
      "♫♫♫ >\n",
      "♫♫♫ > ...waiting for response from OpenGrid Network... \n",
      "♫♫♫ > \u001b[92mDONE!\u001b[0m\n",
      "\n",
      "♫♫♫ > \u001b[92mCONNECTED!\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "duet2 = sy.join_duet(loopback=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "wanted-upper",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Tags</th>\n",
       "      <th>Description</th>\n",
       "      <th>object_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&lt;UID: 4afd379c5ece44ffa6d75a0769a5ff1e&gt;</td>\n",
       "      <td>[DO1 data]</td>\n",
       "      <td>Dataset of 6 samples, 1 feature</td>\n",
       "      <td>&lt;class 'torch.Tensor'&gt;</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        ID        Tags  \\\n",
       "0  <UID: 4afd379c5ece44ffa6d75a0769a5ff1e>  [DO1 data]   \n",
       "\n",
       "                       Description             object_type  \n",
       "0  Dataset of 6 samples, 1 feature  <class 'torch.Tensor'>  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "duet1.store.pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "going-exposure",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Tags</th>\n",
       "      <th>Description</th>\n",
       "      <th>object_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&lt;UID: e23381681cc44cf99c3f6b01f7d9c8bd&gt;</td>\n",
       "      <td>[DO2 data]</td>\n",
       "      <td>Dataset of 5 samples, 1 feature</td>\n",
       "      <td>&lt;class 'torch.Tensor'&gt;</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        ID        Tags  \\\n",
       "0  <UID: e23381681cc44cf99c3f6b01f7d9c8bd>  [DO2 data]   \n",
       "\n",
       "                       Description             object_type  \n",
       "0  Dataset of 5 samples, 1 feature  <class 'torch.Tensor'>  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "duet2.store.pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "responsible-cradle",
   "metadata": {},
   "source": [
    "## Linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "qualified-technical",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<syft.proxy.torch.TensorPointer object at 0x7f56b05a1af0>\n",
      "<syft.proxy.torch.TensorPointer object at 0x7f575c58ed60>\n"
     ]
    }
   ],
   "source": [
    "data1_ptr = duet1.store[0]\n",
    "data2_ptr = duet2.store[0]\n",
    "\n",
    "print(data1_ptr)\n",
    "print(data2_ptr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "seeing-savage",
   "metadata": {},
   "source": [
    "### Create Base Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bizarre-portland",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "advised-federal",
   "metadata": {},
   "outputs": [],
   "source": [
    "in_dim = 1\n",
    "out_dim = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "sapphire-personal",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SyNet(sy.Module):\n",
    "    def __init__(self, torch_ref):\n",
    "        super(SyNet, self).__init__(torch_ref=torch_ref)\n",
    "        self.linear = self.torch_ref.nn.Linear(in_dim, out_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.linear(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rubber-factor",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "chinese-amount",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(iterations, model, torch_ref, optim, data_ptr, target_ptr):\n",
    "\n",
    "    losses = []\n",
    "\n",
    "    for i in range(iterations):\n",
    "\n",
    "        optim.zero_grad()\n",
    "\n",
    "        output = model(data_ptr)\n",
    "\n",
    "        loss = torch_ref.nn.functional.mse_loss(output, target_ptr)\n",
    "\n",
    "        loss_item = loss.item()\n",
    "\n",
    "        loss_value = loss_item.get(\n",
    "            reason=\"To evaluate training progress\",\n",
    "            request_block=True,\n",
    "            timeout_secs=5,\n",
    "        )\n",
    "\n",
    "        print(\"Epoch\", i, \"loss\", loss_value)\n",
    "\n",
    "        losses.append(loss_value)\n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "        optim.step()\n",
    "\n",
    "    return losses"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "creative-guide",
   "metadata": {},
   "source": [
    "#### Send one copy of the model to each data owner or client and train them remotely one by one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "virgin-dayton",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch as th\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "proved-tumor",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = SyNet(torch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "armed-partner",
   "metadata": {},
   "source": [
    "Train on Data Owner 1 data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "convinced-rogers",
   "metadata": {},
   "outputs": [],
   "source": [
    "remote_model1 = base_model.send(duet1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cordless-singles",
   "metadata": {},
   "outputs": [],
   "source": [
    "remote_torch1 = duet1.torch\n",
    "params = remote_model1.parameters()\n",
    "optim1 = remote_torch1.optim.Adam(params=params, lr=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "average-spirit",
   "metadata": {},
   "source": [
    "Dummy target data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "weird-carrier",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 5.],\n",
       "        [10.],\n",
       "        [15.],\n",
       "        [22.],\n",
       "        [30.],\n",
       "        [38.]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target1_ptr = th.FloatTensor(np.array([5, 10, 15, 22, 30, 38]).reshape(-1, 1))\n",
    "target1_ptr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "clinical-cement",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 loss 1187.21923828125\n",
      "Epoch 1 loss 956.0552368164062\n",
      "Epoch 2 loss 750.7745971679688\n",
      "Epoch 3 loss 571.6748657226562\n",
      "Epoch 4 loss 418.8005676269531\n",
      "Epoch 5 loss 291.87554931640625\n",
      "Epoch 6 loss 190.22999572753906\n",
      "Epoch 7 loss 112.7268295288086\n",
      "Epoch 8 loss 57.6978645324707\n",
      "Epoch 9 loss 22.907203674316406\n"
     ]
    }
   ],
   "source": [
    "iteration = 10\n",
    "losses = train(iteration, remote_model1, remote_torch1, optim1, data1_ptr, target1_ptr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "moral-election",
   "metadata": {},
   "source": [
    "Train on Data Owner 2 data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "continental-carter",
   "metadata": {},
   "outputs": [],
   "source": [
    "remote_model2 = base_model.send(duet2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cellular-century",
   "metadata": {},
   "outputs": [],
   "source": [
    "remote_torch2 = duet2.torch\n",
    "params = remote_model2.parameters()\n",
    "optim2 = remote_torch2.optim.Adam(params=params, lr=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "corporate-material",
   "metadata": {},
   "source": [
    "Dummy Target data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "unlikely-digest",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[35.],\n",
       "        [40.],\n",
       "        [45.],\n",
       "        [55.],\n",
       "        [60.]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target2_ptr = th.FloatTensor(np.array([35, 40, 45, 55, 60]).reshape(-1, 1))\n",
    "target2_ptr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "loose-aging",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 loss 5483.63623046875\n",
      "Epoch 1 loss 4388.87255859375\n",
      "Epoch 2 loss 3420.020751953125\n",
      "Epoch 3 loss 2578.491943359375\n",
      "Epoch 4 loss 1864.404541015625\n",
      "Epoch 5 loss 1276.2349853515625\n",
      "Epoch 6 loss 810.4337158203125\n",
      "Epoch 7 loss 461.0394592285156\n",
      "Epoch 8 loss 219.3572998046875\n",
      "Epoch 9 loss 73.79032135009766\n"
     ]
    }
   ],
   "source": [
    "iteration = 10\n",
    "losses = train(iteration, remote_model2, remote_torch2, optim2, data2_ptr, target2_ptr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "grave-gravity",
   "metadata": {},
   "source": [
    "### Averaging Model Updates"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "closed-bangladesh",
   "metadata": {},
   "source": [
    "Ideally, there will be a coordinator server with a secure aggreagtor who will get the model updates from different clients and make an aggregation. For the case of simplicity, in this example we will make the Data Sceintist server work as the coordinator."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hearing-passage",
   "metadata": {},
   "source": [
    "### Little sanity check!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "eastern-silicon",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base Model parameters:\n",
      "[Parameter containing:\n",
      "tensor([[-0.3472]], requires_grad=True), Parameter containing:\n",
      "tensor([0.6145], requires_grad=True)]\n",
      "\n",
      "Remote model1 parameters:\n",
      "[Parameter containing:\n",
      "tensor([[0.5725]], requires_grad=True), Parameter containing:\n",
      "tensor([1.5323], requires_grad=True)]\n",
      "\n",
      "Remote model2 parameters:\n",
      "[Parameter containing:\n",
      "tensor([[0.5686]], requires_grad=True), Parameter containing:\n",
      "tensor([1.5297], requires_grad=True)]\n"
     ]
    }
   ],
   "source": [
    "param1 = remote_model1.parameters().get(request_block=True)\n",
    "param2 = remote_model2.parameters().get(request_block=True)\n",
    "\n",
    "print(\"Base Model parameters:\")\n",
    "print(base_model.parameters())\n",
    "print()\n",
    "\n",
    "print(\"Remote model1 parameters:\")\n",
    "print(param1)\n",
    "print()\n",
    "\n",
    "print(\"Remote model2 parameters:\")\n",
    "print(param2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "preceding-beijing",
   "metadata": {},
   "source": [
    "As you can see, the remote model paramter values are different from the base model paramter values. That means the remote copies of our base model got trained and updated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "afraid-bishop",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([('linear.weight', tensor([[0.5725]])), ('linear.bias', tensor([1.5323]))])\n"
     ]
    }
   ],
   "source": [
    "#request block true means the bock get download and save th\n",
    "remote_model1_updates = remote_model1.get(\n",
    "    request_block=True\n",
    ").state_dict()\n",
    "\n",
    "print(remote_model1_updates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1acef63b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parameter containing:\n",
       " tensor([[0.5725]], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([1.5323], requires_grad=True)]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "remote_model1.get(\n",
    "    request_block=True\n",
    ").parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "limiting-slope",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([('linear.weight', tensor([[0.5686]])), ('linear.bias', tensor([1.5297]))])\n"
     ]
    }
   ],
   "source": [
    "remote_model2_updates = remote_model2.get(\n",
    "    request_block=True\n",
    ").state_dict()\n",
    "\n",
    "print(remote_model2_updates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "personalized-measure",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "apparent-platform",
   "metadata": {},
   "source": [
    "Let's do the aggregation of the weights. In this example, we will just calculate the average of corresponding weights from each model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "experimental-pulse",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([('linear.weight', tensor([[0.5706]])), ('linear.bias', tensor([1.5310]))])\n"
     ]
    }
   ],
   "source": [
    "avg_updates = OrderedDict()\n",
    "avg_updates[\"linear.weight\"] = (\n",
    "    remote_model1_updates[\"linear.weight\"] + remote_model2_updates[\"linear.weight\"]\n",
    ") / 2\n",
    "avg_updates[\"linear.bias\"] = (\n",
    "    remote_model1_updates[\"linear.bias\"] + remote_model2_updates[\"linear.bias\"]\n",
    ") / 2\n",
    "\n",
    "print(avg_updates)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "approximate-scotland",
   "metadata": {},
   "source": [
    "### Load aggregated weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "hungarian-chess",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_model = SyNet(torch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "exempt-gathering",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_model.load_state_dict(avg_updates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "beautiful-coating",
   "metadata": {},
   "outputs": [],
   "source": [
    "del avg_updates, remote_model1_updates, remote_model2_updates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "compressed-employer",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = th.FloatTensor(np.array([17, 25, 32, 50, 80]).reshape(-1, 1))\n",
    "test_target = th.FloatTensor(np.array([12, 15, 20, 30, 50]).reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "assured-amount",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: 11.230474472045898 Ground Truth: 12.0\n",
      "Prediction: 15.794936180114746 Ground Truth: 15.0\n",
      "Prediction: 19.78883934020996 Ground Truth: 20.0\n",
      "Prediction: 30.05887794494629 Ground Truth: 30.0\n",
      "Prediction: 47.17560577392578 Ground Truth: 50.0\n"
     ]
    }
   ],
   "source": [
    "preds = []\n",
    "with torch.no_grad():\n",
    "    for i in range(len(test_data)):\n",
    "        sample = test_data[i]\n",
    "        y_hat = combined_model(sample)\n",
    "\n",
    "        print(f\"Prediction: {y_hat.item()} Ground Truth: {test_target[i].item()}\")\n",
    "        preds.append(y_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "charged-dragon",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: -5.287985801696777 Ground Truth: 12.0\n",
      "Prediction: -8.065629959106445 Ground Truth: 15.0\n",
      "Prediction: -10.496068954467773 Ground Truth: 20.0\n",
      "Prediction: -16.74576759338379 Ground Truth: 30.0\n",
      "Prediction: -27.16193389892578 Ground Truth: 50.0\n"
     ]
    }
   ],
   "source": [
    "preds = []\n",
    "with torch.no_grad():\n",
    "    for i in range(len(test_data)):\n",
    "        sample = test_data[i]\n",
    "        y_hat = base_model(sample)\n",
    "\n",
    "        print(f\"Prediction: {y_hat.item()} Ground Truth: {test_target[i].item()}\")\n",
    "        preds.append(y_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "loose-textbook",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "genetic-diploma",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "documented-italy",
   "metadata": {},
   "source": [
    "## Comparison to classical linear regression on centralised data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "external-recommendation",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "in_dim = 1\n",
    "out_dim = 1\n",
    "\n",
    "\n",
    "class ClassicalLR(torch.nn.Module):\n",
    "    def __init__(self, torch):\n",
    "        super(ClassicalLR, self).__init__()\n",
    "        self.linear = torch.nn.Linear(in_dim, out_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.linear(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "classical_model = ClassicalLR(torch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "featured-antibody",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = torch.FloatTensor(\n",
    "    np.array([5, 15, 25, 35, 45, 55, 60, 65, 75, 85, 95]).reshape(-1, 1)\n",
    ")\n",
    "target = torch.FloatTensor(\n",
    "    np.array([5, 10, 15, 22, 30, 38, 35, 40, 45, 55, 60]).reshape(-1, 1)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "adopted-costs",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classic_train(iterations, model, torch, optim, data, target, criterion):\n",
    "\n",
    "    losses = []\n",
    "\n",
    "    for i in range(iterations):\n",
    "\n",
    "        optim.zero_grad()\n",
    "\n",
    "        output = model(data)\n",
    "\n",
    "        loss = criterion(output, target)\n",
    "\n",
    "        loss_item = loss.item()\n",
    "\n",
    "        if i % 10 == 0:\n",
    "            print(\"Epoch\", i, \"loss\", loss_item)\n",
    "\n",
    "        losses.append(loss_item)\n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "        optim.step()\n",
    "\n",
    "    return losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "balanced-lawyer",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = classical_model.parameters()\n",
    "optim = torch.optim.Adam(params=params, lr=0.1)\n",
    "criterion = torch.nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "technical-gasoline",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 loss 155.32406616210938\n",
      "Epoch 10 loss 5.576186656951904\n",
      "Epoch 20 loss 10.015868186950684\n",
      "Epoch 30 loss 6.7609357833862305\n",
      "Epoch 40 loss 3.4427340030670166\n",
      "Epoch 50 loss 3.3968307971954346\n",
      "Epoch 60 loss 3.2446601390838623\n",
      "Epoch 70 loss 3.108318567276001\n",
      "Epoch 80 loss 3.0627920627593994\n",
      "Epoch 90 loss 3.031777858734131\n"
     ]
    }
   ],
   "source": [
    "iteration = 100\n",
    "losses = classic_train(\n",
    "    iteration, classical_model, torch, optim, data, target, criterion\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "compound-airline",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = th.FloatTensor(np.array([17, 25, 32, 50, 80]).reshape(-1, 1))\n",
    "test_target = th.FloatTensor(np.array([12, 15, 20, 30, 50]).reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "prospective-blood",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: 10.930621147155762 Ground Truth: 12.0\n",
      "Prediction: 15.931267738342285 Ground Truth: 15.0\n",
      "Prediction: 20.306833267211914 Ground Truth: 20.0\n",
      "Prediction: 31.55828857421875 Ground Truth: 30.0\n",
      "Prediction: 50.31071472167969 Ground Truth: 50.0\n"
     ]
    }
   ],
   "source": [
    "preds = []\n",
    "with torch.no_grad():\n",
    "    for i in range(len(test_data)):\n",
    "        sample = test_data[i]\n",
    "        y_hat = classical_model(sample)\n",
    "\n",
    "        print(f\"Prediction: {y_hat.item()} Ground Truth: {test_target[i].item()}\")\n",
    "        preds.append(y_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "veterinary-makeup",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b7253f6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
