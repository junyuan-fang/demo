{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%config Completer.use_jedi = False\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Arguments():\n",
    "    def __init__(self):\n",
    "        self.batch_size = 64\n",
    "        self.test_batch_size = 64\n",
    "        self.epochs = 20\n",
    "        self.lr = 0.02\n",
    "        self.seed = 1\n",
    "        self.log_interval = 1 # Log info at each batch\n",
    "        self.precision_fractional = 3\n",
    "\n",
    "args = Arguments()\n",
    "\n",
    "_ = torch.manual_seed(args.seed)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PySft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import syft as sy  # import the Pysyft library\n",
    "hook = sy.TorchHook(torch)  # hook PyTorch to add extra functionalities like Federated and Encrypted Learning\n",
    "\n",
    "# simulation functions\n",
    "def connect_to_workers(n_workers):\n",
    "    return [\n",
    "        sy.VirtualWorker(hook, id=f\"worker{i+1}\")\n",
    "        for i in range(n_workers)\n",
    "    ]\n",
    "def connect_to_crypto_provider():\n",
    "    return sy.VirtualWorker(hook, id=\"crypto_provider\")\n",
    "\n",
    "workers = connect_to_workers(n_workers=2)\n",
    "crypto_provider = connect_to_crypto_provider()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Access and secret\n",
    "The workers then split their data in batches and secret share their data between each others. \n",
    "Local worker (like us) never had access to the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1.1%"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ../data/MNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.1%"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ../data/MNIST/raw/train-images-idx3-ubyte.gz to ../data/MNIST/raw\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5.5%5%"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ../data/MNIST/raw/train-labels-idx1-ubyte.gz\n",
      "Extracting ../data/MNIST/raw/train-labels-idx1-ubyte.gz to ../data/MNIST/raw\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ../data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "180.4%"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ../data/MNIST/raw/t10k-images-idx3-ubyte.gz to ../data/MNIST/raw\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ../data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n",
      "Extracting ../data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ../data/MNIST/raw\n",
      "Processing...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "# We don't use the whole dataset for efficiency purpose, but feel free to increase these numbers\n",
    "n_train_items = 640#can be changed\n",
    "n_test_items = 640#can be changed\n",
    "\n",
    "def get_private_data_loaders(precision_fractional, workers, crypto_provider):\n",
    "    \n",
    "    def one_hot_of(index_tensor):\n",
    "        \"\"\"\n",
    "        Transform to one hot tensor\n",
    "        \n",
    "        Example:\n",
    "            [0, 3, 9]\n",
    "            =>\n",
    "            [[1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
    "             [0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
    "             [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]]\n",
    "            \n",
    "        \"\"\"\n",
    "        onehot_tensor = torch.zeros(*index_tensor.shape, 10) # 10 classes for MNIST\n",
    "        onehot_tensor = onehot_tensor.scatter(1, index_tensor.view(-1, 1), 1)\n",
    "        return onehot_tensor\n",
    "        \n",
    "    def secret_share(tensor):\n",
    "        \"\"\"\n",
    "        Transform to fixed precision and secret share a tensor\n",
    "        \"\"\"\n",
    "        return (\n",
    "            tensor\n",
    "            .fix_precision(precision_fractional=precision_fractional)\n",
    "            .share(*workers, crypto_provider=crypto_provider, requires_grad=True)\n",
    "        )\n",
    "    \n",
    "    transformation = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.1307,), (0.3081,))\n",
    "    ])\n",
    "    \n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        datasets.MNIST('../data', train=True, download=True, transform=transformation),\n",
    "        batch_size=args.batch_size\n",
    "    )\n",
    "    \n",
    "    private_train_loader = [\n",
    "        (secret_share(data), secret_share(one_hot_of(target)))\n",
    "        for i, (data, target) in enumerate(train_loader)\n",
    "        if i < n_train_items / args.batch_size\n",
    "    ]\n",
    "    \n",
    "    test_loader = torch.utils.data.DataLoader(\n",
    "        datasets.MNIST('../data', train=False, download=True, transform=transformation),\n",
    "        batch_size=args.test_batch_size\n",
    "    )\n",
    "    \n",
    "    private_test_loader = [\n",
    "        (secret_share(data), secret_share(target.float()))\n",
    "        for i, (data, target) in enumerate(test_loader)\n",
    "        if i < n_test_items / args.test_batch_size\n",
    "    ]\n",
    "    \n",
    "    return private_train_loader, private_test_loader\n",
    "    \n",
    "    \n",
    "private_train_loader, private_test_loader = get_private_data_loaders(\n",
    "    precision_fractional=args.precision_fractional,\n",
    "    workers=workers,\n",
    "    crypto_provider=crypto_provider\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model specification\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(28 * 28, 128)\n",
    "        self.fc2 = nn.Linear(128, 64)\n",
    "        self.fc3 = nn.Linear(64, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 28 * 28)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training and testing functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(args, model, private_train_loader, optimizer, epoch):\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(private_train_loader): # <-- now it is a private dataset\n",
    "        start_time = time.time()\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        output = model(data)\n",
    "        \n",
    "        # loss = F.nll_loss(output, target)  <-- not possible here\n",
    "        batch_size = output.shape[0]\n",
    "        loss = ((output - target)**2).sum().refresh()/batch_size\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "\n",
    "        if batch_idx % args.log_interval == 0:\n",
    "            loss = loss.get().float_precision()\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}\\tTime: {:.3f}s'.format(\n",
    "                epoch, batch_idx * args.batch_size, len(private_train_loader) * args.batch_size,\n",
    "                100. * batch_idx / len(private_train_loader), loss.item(), time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(args, model, private_test_loader):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in private_test_loader:\n",
    "            start_time = time.time()\n",
    "            \n",
    "            output = model(data)\n",
    "            pred = output.argmax(dim=1)\n",
    "            correct += pred.eq(target.view_as(pred)).sum()\n",
    "\n",
    "    correct = correct.get().float_precision()\n",
    "    print('\\nTest set: Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        correct.item(), len(private_test_loader)* args.test_batch_size,\n",
    "        100. * correct.item() / (len(private_test_loader) * args.test_batch_size)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trainning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fjunyuan/.local/lib/python3.8/site-packages/syft/frameworks/torch/tensors/interpreters/additive_shared.py:122: UserWarning: Use dtype instead of field\n",
      "  warnings.warn(\"Use dtype instead of field\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/640 (0%)]\tLoss: 1.128000\tTime: 7.122s\n",
      "Train Epoch: 1 [64/640 (10%)]\tLoss: 1.013000\tTime: 8.410s\n",
      "Train Epoch: 1 [128/640 (20%)]\tLoss: 0.988000\tTime: 8.142s\n",
      "Train Epoch: 1 [192/640 (30%)]\tLoss: 0.901000\tTime: 7.185s\n",
      "Train Epoch: 1 [256/640 (40%)]\tLoss: 0.887000\tTime: 6.988s\n",
      "Train Epoch: 1 [320/640 (50%)]\tLoss: 0.875000\tTime: 7.344s\n",
      "Train Epoch: 1 [384/640 (60%)]\tLoss: 0.852000\tTime: 7.173s\n",
      "Train Epoch: 1 [448/640 (70%)]\tLoss: 0.849000\tTime: 7.142s\n",
      "Train Epoch: 1 [512/640 (80%)]\tLoss: 0.829000\tTime: 8.226s\n",
      "Train Epoch: 1 [576/640 (90%)]\tLoss: 0.839000\tTime: 8.102s\n",
      "\n",
      "Test set: Accuracy: 233.0/640 (36%)\n",
      "\n",
      "Train Epoch: 2 [0/640 (0%)]\tLoss: 0.777000\tTime: 7.340s\n",
      "Train Epoch: 2 [64/640 (10%)]\tLoss: 0.732000\tTime: 7.606s\n",
      "Train Epoch: 2 [128/640 (20%)]\tLoss: 0.792000\tTime: 8.453s\n",
      "Train Epoch: 2 [192/640 (30%)]\tLoss: 0.713000\tTime: 8.054s\n",
      "Train Epoch: 2 [256/640 (40%)]\tLoss: 0.701000\tTime: 7.574s\n",
      "Train Epoch: 2 [320/640 (50%)]\tLoss: 0.705000\tTime: 7.435s\n",
      "Train Epoch: 2 [384/640 (60%)]\tLoss: 0.704000\tTime: 7.949s\n",
      "Train Epoch: 2 [448/640 (70%)]\tLoss: 0.714000\tTime: 7.650s\n",
      "Train Epoch: 2 [512/640 (80%)]\tLoss: 0.709000\tTime: 7.618s\n",
      "Train Epoch: 2 [576/640 (90%)]\tLoss: 0.742000\tTime: 7.692s\n",
      "\n",
      "Test set: Accuracy: 359.0/640 (56%)\n",
      "\n",
      "Train Epoch: 3 [0/640 (0%)]\tLoss: 0.668000\tTime: 6.621s\n",
      "Train Epoch: 3 [64/640 (10%)]\tLoss: 0.598000\tTime: 6.548s\n",
      "Train Epoch: 3 [128/640 (20%)]\tLoss: 0.696000\tTime: 6.273s\n",
      "Train Epoch: 3 [192/640 (30%)]\tLoss: 0.601000\tTime: 7.431s\n",
      "Train Epoch: 3 [256/640 (40%)]\tLoss: 0.584000\tTime: 6.623s\n",
      "Train Epoch: 3 [320/640 (50%)]\tLoss: 0.597000\tTime: 6.638s\n",
      "Train Epoch: 3 [384/640 (60%)]\tLoss: 0.605000\tTime: 6.403s\n",
      "Train Epoch: 3 [448/640 (70%)]\tLoss: 0.625000\tTime: 6.455s\n",
      "Train Epoch: 3 [512/640 (80%)]\tLoss: 0.623000\tTime: 6.311s\n",
      "Train Epoch: 3 [576/640 (90%)]\tLoss: 0.670000\tTime: 6.066s\n",
      "\n",
      "Test set: Accuracy: 401.0/640 (63%)\n",
      "\n",
      "Train Epoch: 4 [0/640 (0%)]\tLoss: 0.586000\tTime: 6.373s\n",
      "Train Epoch: 4 [64/640 (10%)]\tLoss: 0.501000\tTime: 6.751s\n",
      "Train Epoch: 4 [128/640 (20%)]\tLoss: 0.620000\tTime: 6.876s\n",
      "Train Epoch: 4 [192/640 (30%)]\tLoss: 0.516000\tTime: 6.587s\n",
      "Train Epoch: 4 [256/640 (40%)]\tLoss: 0.507000\tTime: 6.195s\n",
      "Train Epoch: 4 [320/640 (50%)]\tLoss: 0.517000\tTime: 6.075s\n",
      "Train Epoch: 4 [384/640 (60%)]\tLoss: 0.535000\tTime: 6.084s\n",
      "Train Epoch: 4 [448/640 (70%)]\tLoss: 0.555000\tTime: 7.216s\n",
      "Train Epoch: 4 [512/640 (80%)]\tLoss: 0.554000\tTime: 6.603s\n",
      "Train Epoch: 4 [576/640 (90%)]\tLoss: 0.612000\tTime: 6.714s\n",
      "\n",
      "Test set: Accuracy: 432.0/640 (68%)\n",
      "\n",
      "Train Epoch: 5 [0/640 (0%)]\tLoss: 0.530000\tTime: 6.788s\n",
      "Train Epoch: 5 [64/640 (10%)]\tLoss: 0.441000\tTime: 6.616s\n",
      "Train Epoch: 5 [128/640 (20%)]\tLoss: 0.570000\tTime: 7.035s\n",
      "Train Epoch: 5 [192/640 (30%)]\tLoss: 0.457000\tTime: 7.138s\n",
      "Train Epoch: 5 [256/640 (40%)]\tLoss: 0.450000\tTime: 6.405s\n",
      "Train Epoch: 5 [320/640 (50%)]\tLoss: 0.458000\tTime: 6.456s\n",
      "Train Epoch: 5 [384/640 (60%)]\tLoss: 0.486000\tTime: 6.544s\n",
      "Train Epoch: 5 [448/640 (70%)]\tLoss: 0.507000\tTime: 6.563s\n",
      "Train Epoch: 5 [512/640 (80%)]\tLoss: 0.503000\tTime: 7.044s\n",
      "Train Epoch: 5 [576/640 (90%)]\tLoss: 0.572000\tTime: 6.831s\n",
      "\n",
      "Test set: Accuracy: 452.0/640 (71%)\n",
      "\n",
      "Train Epoch: 6 [0/640 (0%)]\tLoss: 0.487000\tTime: 7.746s\n",
      "Train Epoch: 6 [64/640 (10%)]\tLoss: 0.390000\tTime: 7.019s\n",
      "Train Epoch: 6 [128/640 (20%)]\tLoss: 0.523000\tTime: 6.706s\n",
      "Train Epoch: 6 [192/640 (30%)]\tLoss: 0.411000\tTime: 6.841s\n",
      "Train Epoch: 6 [256/640 (40%)]\tLoss: 0.409000\tTime: 6.239s\n",
      "Train Epoch: 6 [320/640 (50%)]\tLoss: 0.411000\tTime: 6.206s\n",
      "Train Epoch: 6 [384/640 (60%)]\tLoss: 0.444000\tTime: 6.623s\n",
      "Train Epoch: 6 [448/640 (70%)]\tLoss: 0.468000\tTime: 6.851s\n",
      "Train Epoch: 6 [512/640 (80%)]\tLoss: 0.462000\tTime: 6.674s\n",
      "Train Epoch: 6 [576/640 (90%)]\tLoss: 0.537000\tTime: 6.838s\n",
      "\n",
      "Test set: Accuracy: 458.0/640 (72%)\n",
      "\n",
      "Train Epoch: 7 [0/640 (0%)]\tLoss: 0.449000\tTime: 6.204s\n",
      "Train Epoch: 7 [64/640 (10%)]\tLoss: 0.353000\tTime: 6.545s\n",
      "Train Epoch: 7 [128/640 (20%)]\tLoss: 0.490000\tTime: 6.274s\n",
      "Train Epoch: 7 [192/640 (30%)]\tLoss: 0.380000\tTime: 6.300s\n",
      "Train Epoch: 7 [256/640 (40%)]\tLoss: 0.377000\tTime: 6.291s\n",
      "Train Epoch: 7 [320/640 (50%)]\tLoss: 0.377000\tTime: 6.267s\n",
      "Train Epoch: 7 [384/640 (60%)]\tLoss: 0.410000\tTime: 6.311s\n",
      "Train Epoch: 7 [448/640 (70%)]\tLoss: 0.438000\tTime: 6.277s\n",
      "Train Epoch: 7 [512/640 (80%)]\tLoss: 0.429000\tTime: 6.243s\n",
      "Train Epoch: 7 [576/640 (90%)]\tLoss: 0.509000\tTime: 6.463s\n",
      "\n",
      "Test set: Accuracy: 464.0/640 (72%)\n",
      "\n",
      "Train Epoch: 8 [0/640 (0%)]\tLoss: 0.418000\tTime: 6.371s\n",
      "Train Epoch: 8 [64/640 (10%)]\tLoss: 0.329000\tTime: 6.285s\n",
      "Train Epoch: 8 [128/640 (20%)]\tLoss: 0.461000\tTime: 6.294s\n",
      "Train Epoch: 8 [192/640 (30%)]\tLoss: 0.349000\tTime: 6.667s\n",
      "Train Epoch: 8 [256/640 (40%)]\tLoss: 0.351000\tTime: 6.367s\n",
      "Train Epoch: 8 [320/640 (50%)]\tLoss: 0.348000\tTime: 6.295s\n",
      "Train Epoch: 8 [384/640 (60%)]\tLoss: 0.382000\tTime: 6.419s\n",
      "Train Epoch: 8 [448/640 (70%)]\tLoss: 0.414000\tTime: 6.328s\n",
      "Train Epoch: 8 [512/640 (80%)]\tLoss: 0.402000\tTime: 6.323s\n",
      "Train Epoch: 8 [576/640 (90%)]\tLoss: 0.485000\tTime: 6.399s\n",
      "\n",
      "Test set: Accuracy: 473.0/640 (74%)\n",
      "\n",
      "Train Epoch: 9 [0/640 (0%)]\tLoss: 0.392000\tTime: 7.137s\n",
      "Train Epoch: 9 [64/640 (10%)]\tLoss: 0.303000\tTime: 7.304s\n",
      "Train Epoch: 9 [128/640 (20%)]\tLoss: 0.437000\tTime: 7.145s\n",
      "Train Epoch: 9 [192/640 (30%)]\tLoss: 0.327000\tTime: 8.104s\n",
      "Train Epoch: 9 [256/640 (40%)]\tLoss: 0.328000\tTime: 7.361s\n",
      "Train Epoch: 9 [320/640 (50%)]\tLoss: 0.322000\tTime: 8.650s\n",
      "Train Epoch: 9 [384/640 (60%)]\tLoss: 0.359000\tTime: 7.486s\n",
      "Train Epoch: 9 [448/640 (70%)]\tLoss: 0.390000\tTime: 6.788s\n",
      "Train Epoch: 9 [512/640 (80%)]\tLoss: 0.378000\tTime: 6.768s\n",
      "Train Epoch: 9 [576/640 (90%)]\tLoss: 0.462000\tTime: 6.895s\n",
      "\n",
      "Test set: Accuracy: 478.0/640 (75%)\n",
      "\n",
      "Train Epoch: 10 [0/640 (0%)]\tLoss: 0.369000\tTime: 7.763s\n",
      "Train Epoch: 10 [64/640 (10%)]\tLoss: 0.284000\tTime: 7.823s\n",
      "Train Epoch: 10 [128/640 (20%)]\tLoss: 0.412000\tTime: 8.615s\n",
      "Train Epoch: 10 [192/640 (30%)]\tLoss: 0.307000\tTime: 6.964s\n",
      "Train Epoch: 10 [256/640 (40%)]\tLoss: 0.310000\tTime: 6.919s\n",
      "Train Epoch: 10 [320/640 (50%)]\tLoss: 0.304000\tTime: 7.292s\n",
      "Train Epoch: 10 [384/640 (60%)]\tLoss: 0.337000\tTime: 7.472s\n",
      "Train Epoch: 10 [448/640 (70%)]\tLoss: 0.371000\tTime: 6.948s\n",
      "Train Epoch: 10 [512/640 (80%)]\tLoss: 0.356000\tTime: 7.138s\n",
      "Train Epoch: 10 [576/640 (90%)]\tLoss: 0.442000\tTime: 8.508s\n",
      "\n",
      "Test set: Accuracy: 487.0/640 (76%)\n",
      "\n",
      "Train Epoch: 11 [0/640 (0%)]\tLoss: 0.349000\tTime: 7.835s\n",
      "Train Epoch: 11 [64/640 (10%)]\tLoss: 0.264000\tTime: 7.415s\n",
      "Train Epoch: 11 [128/640 (20%)]\tLoss: 0.388000\tTime: 9.328s\n",
      "Train Epoch: 11 [192/640 (30%)]\tLoss: 0.287000\tTime: 9.295s\n",
      "Train Epoch: 11 [256/640 (40%)]\tLoss: 0.291000\tTime: 7.787s\n",
      "Train Epoch: 11 [320/640 (50%)]\tLoss: 0.284000\tTime: 8.170s\n",
      "Train Epoch: 11 [384/640 (60%)]\tLoss: 0.320000\tTime: 8.380s\n",
      "Train Epoch: 11 [448/640 (70%)]\tLoss: 0.352000\tTime: 7.215s\n",
      "Train Epoch: 11 [512/640 (80%)]\tLoss: 0.340000\tTime: 7.226s\n",
      "Train Epoch: 11 [576/640 (90%)]\tLoss: 0.423000\tTime: 7.814s\n",
      "\n",
      "Test set: Accuracy: 483.0/640 (75%)\n",
      "\n",
      "Train Epoch: 12 [0/640 (0%)]\tLoss: 0.331000\tTime: 6.787s\n",
      "Train Epoch: 12 [64/640 (10%)]\tLoss: 0.250000\tTime: 6.820s\n",
      "Train Epoch: 12 [128/640 (20%)]\tLoss: 0.367000\tTime: 6.936s\n",
      "Train Epoch: 12 [192/640 (30%)]\tLoss: 0.273000\tTime: 6.909s\n",
      "Train Epoch: 12 [256/640 (40%)]\tLoss: 0.276000\tTime: 6.907s\n",
      "Train Epoch: 12 [320/640 (50%)]\tLoss: 0.266000\tTime: 6.877s\n",
      "Train Epoch: 12 [384/640 (60%)]\tLoss: 0.304000\tTime: 6.877s\n",
      "Train Epoch: 12 [448/640 (70%)]\tLoss: 0.336000\tTime: 7.158s\n",
      "Train Epoch: 12 [512/640 (80%)]\tLoss: 0.322000\tTime: 6.925s\n",
      "Train Epoch: 12 [576/640 (90%)]\tLoss: 0.405000\tTime: 6.819s\n",
      "\n",
      "Test set: Accuracy: 494.0/640 (77%)\n",
      "\n",
      "Train Epoch: 13 [0/640 (0%)]\tLoss: 0.314000\tTime: 6.896s\n",
      "Train Epoch: 13 [64/640 (10%)]\tLoss: 0.237000\tTime: 6.916s\n",
      "Train Epoch: 13 [128/640 (20%)]\tLoss: 0.349000\tTime: 7.229s\n",
      "Train Epoch: 13 [192/640 (30%)]\tLoss: 0.258000\tTime: 7.992s\n",
      "Train Epoch: 13 [256/640 (40%)]\tLoss: 0.261000\tTime: 6.925s\n",
      "Train Epoch: 13 [320/640 (50%)]\tLoss: 0.254000\tTime: 6.963s\n",
      "Train Epoch: 13 [384/640 (60%)]\tLoss: 0.287000\tTime: 7.002s\n",
      "Train Epoch: 13 [448/640 (70%)]\tLoss: 0.322000\tTime: 6.905s\n",
      "Train Epoch: 13 [512/640 (80%)]\tLoss: 0.305000\tTime: 6.927s\n",
      "Train Epoch: 13 [576/640 (90%)]\tLoss: 0.388000\tTime: 6.949s\n",
      "\n",
      "Test set: Accuracy: 496.0/640 (78%)\n",
      "\n",
      "Train Epoch: 14 [0/640 (0%)]\tLoss: 0.300000\tTime: 6.901s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 14 [64/640 (10%)]\tLoss: 0.220000\tTime: 6.950s\n",
      "Train Epoch: 14 [128/640 (20%)]\tLoss: 0.331000\tTime: 6.993s\n",
      "Train Epoch: 14 [192/640 (30%)]\tLoss: 0.247000\tTime: 7.179s\n",
      "Train Epoch: 14 [256/640 (40%)]\tLoss: 0.247000\tTime: 7.014s\n",
      "Train Epoch: 14 [320/640 (50%)]\tLoss: 0.239000\tTime: 7.028s\n",
      "Train Epoch: 14 [384/640 (60%)]\tLoss: 0.272000\tTime: 6.929s\n",
      "Train Epoch: 14 [448/640 (70%)]\tLoss: 0.309000\tTime: 6.988s\n",
      "Train Epoch: 14 [512/640 (80%)]\tLoss: 0.291000\tTime: 7.034s\n",
      "Train Epoch: 14 [576/640 (90%)]\tLoss: 0.377000\tTime: 7.001s\n",
      "\n",
      "Test set: Accuracy: 504.0/640 (79%)\n",
      "\n",
      "Train Epoch: 15 [0/640 (0%)]\tLoss: 0.291000\tTime: 7.039s\n",
      "Train Epoch: 15 [64/640 (10%)]\tLoss: 0.208000\tTime: 6.992s\n",
      "Train Epoch: 15 [128/640 (20%)]\tLoss: 0.314000\tTime: 7.036s\n",
      "Train Epoch: 15 [192/640 (30%)]\tLoss: 0.236000\tTime: 7.072s\n",
      "Train Epoch: 15 [256/640 (40%)]\tLoss: 0.235000\tTime: 7.077s\n",
      "Train Epoch: 15 [320/640 (50%)]\tLoss: 0.226000\tTime: 7.032s\n",
      "Train Epoch: 15 [384/640 (60%)]\tLoss: 0.258000\tTime: 7.343s\n",
      "Train Epoch: 15 [448/640 (70%)]\tLoss: 0.293000\tTime: 7.019s\n",
      "Train Epoch: 15 [512/640 (80%)]\tLoss: 0.278000\tTime: 7.064s\n",
      "Train Epoch: 15 [576/640 (90%)]\tLoss: 0.364000\tTime: 7.069s\n",
      "\n",
      "Test set: Accuracy: 508.0/640 (79%)\n",
      "\n",
      "Train Epoch: 16 [0/640 (0%)]\tLoss: 0.278000\tTime: 7.092s\n",
      "Train Epoch: 16 [64/640 (10%)]\tLoss: 0.200000\tTime: 7.145s\n",
      "Train Epoch: 16 [128/640 (20%)]\tLoss: 0.300000\tTime: 7.013s\n",
      "Train Epoch: 16 [192/640 (30%)]\tLoss: 0.226000\tTime: 7.920s\n",
      "Train Epoch: 16 [256/640 (40%)]\tLoss: 0.227000\tTime: 7.374s\n",
      "Train Epoch: 16 [320/640 (50%)]\tLoss: 0.216000\tTime: 7.303s\n",
      "Train Epoch: 16 [384/640 (60%)]\tLoss: 0.247000\tTime: 7.307s\n",
      "Train Epoch: 16 [448/640 (70%)]\tLoss: 0.282000\tTime: 7.375s\n",
      "Train Epoch: 16 [512/640 (80%)]\tLoss: 0.265000\tTime: 7.386s\n",
      "Train Epoch: 16 [576/640 (90%)]\tLoss: 0.348000\tTime: 7.394s\n",
      "\n",
      "Test set: Accuracy: 511.0/640 (80%)\n",
      "\n",
      "Train Epoch: 17 [0/640 (0%)]\tLoss: 0.262000\tTime: 7.460s\n",
      "Train Epoch: 17 [64/640 (10%)]\tLoss: 0.189000\tTime: 7.381s\n",
      "Train Epoch: 17 [128/640 (20%)]\tLoss: 0.291000\tTime: 7.614s\n",
      "Train Epoch: 17 [192/640 (30%)]\tLoss: 0.215000\tTime: 7.529s\n",
      "Train Epoch: 17 [256/640 (40%)]\tLoss: 0.216000\tTime: 7.486s\n",
      "Train Epoch: 17 [320/640 (50%)]\tLoss: 0.204000\tTime: 7.482s\n",
      "Train Epoch: 17 [384/640 (60%)]\tLoss: 0.235000\tTime: 7.442s\n",
      "Train Epoch: 17 [448/640 (70%)]\tLoss: 0.270000\tTime: 7.478s\n",
      "Train Epoch: 17 [512/640 (80%)]\tLoss: 0.252000\tTime: 7.449s\n",
      "Train Epoch: 17 [576/640 (90%)]\tLoss: 0.335000\tTime: 7.495s\n",
      "\n",
      "Test set: Accuracy: 511.0/640 (80%)\n",
      "\n",
      "Train Epoch: 18 [0/640 (0%)]\tLoss: 0.253000\tTime: 7.538s\n",
      "Train Epoch: 18 [64/640 (10%)]\tLoss: 0.181000\tTime: 7.501s\n",
      "Train Epoch: 18 [128/640 (20%)]\tLoss: 0.276000\tTime: 7.586s\n",
      "Train Epoch: 18 [192/640 (30%)]\tLoss: 0.207000\tTime: 7.567s\n",
      "Train Epoch: 18 [256/640 (40%)]\tLoss: 0.206000\tTime: 7.521s\n",
      "Train Epoch: 18 [320/640 (50%)]\tLoss: 0.194000\tTime: 7.555s\n",
      "Train Epoch: 18 [384/640 (60%)]\tLoss: 0.223000\tTime: 7.568s\n",
      "Train Epoch: 18 [448/640 (70%)]\tLoss: 0.260000\tTime: 7.519s\n",
      "Train Epoch: 18 [512/640 (80%)]\tLoss: 0.242000\tTime: 7.588s\n",
      "Train Epoch: 18 [576/640 (90%)]\tLoss: 0.324000\tTime: 7.988s\n",
      "\n",
      "Test set: Accuracy: 516.0/640 (81%)\n",
      "\n",
      "Train Epoch: 19 [0/640 (0%)]\tLoss: 0.243000\tTime: 7.536s\n",
      "Train Epoch: 19 [64/640 (10%)]\tLoss: 0.172000\tTime: 7.566s\n",
      "Train Epoch: 19 [128/640 (20%)]\tLoss: 0.266000\tTime: 7.658s\n",
      "Train Epoch: 19 [192/640 (30%)]\tLoss: 0.200000\tTime: 7.570s\n",
      "Train Epoch: 19 [256/640 (40%)]\tLoss: 0.197000\tTime: 8.042s\n",
      "Train Epoch: 19 [320/640 (50%)]\tLoss: 0.185000\tTime: 7.618s\n",
      "Train Epoch: 19 [384/640 (60%)]\tLoss: 0.216000\tTime: 7.622s\n",
      "Train Epoch: 19 [448/640 (70%)]\tLoss: 0.251000\tTime: 7.597s\n",
      "Train Epoch: 19 [512/640 (80%)]\tLoss: 0.231000\tTime: 7.635s\n",
      "Train Epoch: 19 [576/640 (90%)]\tLoss: 0.313000\tTime: 7.671s\n",
      "\n",
      "Test set: Accuracy: 519.0/640 (81%)\n",
      "\n",
      "Train Epoch: 20 [0/640 (0%)]\tLoss: 0.235000\tTime: 7.509s\n",
      "Train Epoch: 20 [64/640 (10%)]\tLoss: 0.167000\tTime: 7.688s\n",
      "Train Epoch: 20 [128/640 (20%)]\tLoss: 0.255000\tTime: 7.711s\n",
      "Train Epoch: 20 [192/640 (30%)]\tLoss: 0.192000\tTime: 7.670s\n",
      "Train Epoch: 20 [256/640 (40%)]\tLoss: 0.191000\tTime: 7.662s\n",
      "Train Epoch: 20 [320/640 (50%)]\tLoss: 0.178000\tTime: 7.614s\n",
      "Train Epoch: 20 [384/640 (60%)]\tLoss: 0.209000\tTime: 7.640s\n",
      "Train Epoch: 20 [448/640 (70%)]\tLoss: 0.241000\tTime: 7.775s\n",
      "Train Epoch: 20 [512/640 (80%)]\tLoss: 0.223000\tTime: 7.693s\n",
      "Train Epoch: 20 [576/640 (90%)]\tLoss: 0.303000\tTime: 8.037s\n",
      "\n",
      "Test set: Accuracy: 515.0/640 (80%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = Net()\n",
    "model = model.fix_precision().share(*workers, crypto_provider=crypto_provider, requires_grad=True)\n",
    "\n",
    "optimizer = optim.SGD(model.parameters(), lr=args.lr)\n",
    "optimizer = optimizer.fix_precision() \n",
    "\n",
    "for epoch in range(1, args.epochs + 1):\n",
    "    train(args, model, private_train_loader, optimizer, epoch)\n",
    "    test(args, model, private_test_loader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
